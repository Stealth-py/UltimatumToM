{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bcfc2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, re, json\n",
    "from ast import literal_eval\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import krippendorff\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from metric_utils import CAC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2f9969",
   "metadata": {},
   "source": [
    "# Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "463bc800",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {\n",
    "    'Model': [],\n",
    "    'Experiment': [],\n",
    "    'Proposer Belief': [],\n",
    "    'Responder Belief': [],\n",
    "    'Proposal': [],\n",
    "    'Proposer Reasoning': [],\n",
    "    'Decision': [],\n",
    "    'Responder Reasoning': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10b0766b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-3.1-8b-instant\n",
      "('greedy', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('fair', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('greedy', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('selfless', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('selfless', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('greedy', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('fair', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('fair', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('selfless', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "gpt-4o\n",
      "('greedy', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('fair', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('greedy', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('selfless', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('selfless', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('greedy', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('fair', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('fair', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('selfless', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "o3-mini\n",
      "('greedy', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('fair', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('greedy', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('selfless', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('selfless', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('greedy', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('fair', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('fair', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('selfless', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "claude-3-5-haiku-20241022\n",
      "('greedy', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('fair', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('greedy', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('selfless', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('selfless', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('greedy', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('fair', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('fair', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('selfless', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "llama-3.3-70b-versatile\n",
      "('greedy', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('fair', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('greedy', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('selfless', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('selfless', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('greedy', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('fair', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('fair', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('selfless', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "deepseek-r1-distill-qwen-32b\n",
      "('greedy', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('fair', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('greedy', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('selfless', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('selfless', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('greedy', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('fair', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('fair', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('selfless', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "gpt-4o-mini\n",
      "('greedy', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('fair', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('greedy', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('selfless', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('selfless', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('greedy', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('fair', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('fair', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n",
      "('selfless', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-zero\n",
      "belief_private_tom-first\n"
     ]
    }
   ],
   "source": [
    "for model in os.listdir('../simulations'):\n",
    "    print(model)\n",
    "    curr_dir = os.path.join('../simulations', model)\n",
    "\n",
    "    if not os.path.isdir(curr_dir):\n",
    "        continue\n",
    "\n",
    "    for setting in [('greedy', 'fair'), ('fair', 'greedy'), ('greedy', 'greedy'), ('selfless', 'greedy'), ('selfless', 'fair'), ('greedy', 'selfless'), ('fair', 'fair'), ('fair', 'selfless'), ('selfless', 'selfless')]:\n",
    "        print(setting)\n",
    "        set_dir = os.path.join(curr_dir, f'{setting[0]}-{setting[1]}')\n",
    "\n",
    "        if not os.path.isdir(set_dir):\n",
    "            continue\n",
    "\n",
    "        for exp in os.listdir(set_dir):\n",
    "            if 'tom' not in exp:\n",
    "                continue\n",
    "            print(exp)\n",
    "            exp_dir = os.path.join(set_dir, exp)\n",
    "            if not os.path.isdir(exp_dir):\n",
    "                continue\n",
    "            \n",
    "            for _ in range(2):\n",
    "                session = random.randint(1, 10)\n",
    "\n",
    "                with open(os.path.join(exp_dir, f'{session}.json'), 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                f.close()\n",
    "\n",
    "                turn = random.randint(0, len(data) - 1)\n",
    "                data = data[turn]\n",
    "\n",
    "                df['Model'].append(model)\n",
    "                df['Experiment'].append(exp.replace('belief_private_', ''))\n",
    "                df['Proposer Belief'].append(setting[0])\n",
    "                df['Responder Belief'].append(setting[1])\n",
    "                df['Proposal'].append(data['proposer'])\n",
    "                df['Proposer Reasoning'].append(data['proposer_tom'])\n",
    "                df['Decision'].append(data['responder'])\n",
    "                df['Responder Reasoning'].append(data['responder_tom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14bb69d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b0ffc86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 8)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e9e5af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_df = df[['Model', 'Experiment', 'Proposer Belief', 'Responder Belief', 'Proposal', 'Proposer Reasoning']]\n",
    "resp_df = df[['Model', 'Experiment', 'Proposer Belief', 'Responder Belief', 'Proposal', 'Decisions', 'Responder Reasoning']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "288f22c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = prop_df[prop_df['Model'] == 'deepseek-r1-distill-qwen-32b'].sample(frac=1).reset_index(drop=True)\n",
    "x2 = prop_df[prop_df['Model'] == 'gpt-4o'].sample(frac=1).reset_index(drop=True)\n",
    "x3 = prop_df[prop_df['Model'] == 'llama-3.3-70b-versatile'].sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c71d0330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neemeshyadav/miniconda/envs/venv/lib/python3.12/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "z1 = np.array_split(x1, 3)\n",
    "z2 = np.array_split(x2, 3)\n",
    "z3 = np.array_split(x3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e36ac17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ver = [pd.DataFrame([]) for _ in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e668bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    df_ver[i] = pd.concat([df_ver[i], z1[i]])\n",
    "    df_ver[i] = pd.concat([df_ver[i], z2[i]])\n",
    "    df_ver[i] = pd.concat([df_ver[i], z3[i]])\n",
    "\n",
    "    df_ver[i]['Proposal Consistency'] = [\"\" for _ in range(54)]\n",
    "    df_ver[i]['Belief Consistency'] = [\"\" for _ in range(54)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f1d5193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ver[0].reset_index(drop=True).to_csv('../human_verification/prop-s1.csv', columns=['Proposer Belief', 'Proposal', 'Proposer Reasoning', 'Proposal Consistency', 'Belief Consistency'])\n",
    "df_ver[1].reset_index(drop=True).to_csv('../human_verification/prop-s2.csv', columns=['Proposer Belief', 'Proposal', 'Proposer Reasoning', 'Proposal Consistency', 'Belief Consistency'])\n",
    "df_ver[2].reset_index(drop=True).to_csv('../human_verification/prop-s3.csv', columns=['Proposer Belief', 'Proposal', 'Proposer Reasoning', 'Proposal Consistency', 'Belief Consistency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd66ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "978b1c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = resp_df[resp_df['Model'] == 'deepseek-r1-distill-qwen-32b'].sample(frac=1).reset_index(drop=True)\n",
    "y2 = resp_df[resp_df['Model'] == 'gpt-4o'].sample(frac=1).reset_index(drop=True)\n",
    "y3 = resp_df[resp_df['Model'] == 'llama-3.3-70b-versatile'].sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fd6434c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neemeshyadav/miniconda/envs/venv/lib/python3.12/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "a1 = np.array_split(y1, 3)\n",
    "a2 = np.array_split(y2, 3)\n",
    "a3 = np.array_split(y3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3d5e39ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ver_r = [pd.DataFrame([]) for _ in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7e7560af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    df_ver_r[i] = pd.concat([df_ver_r[i], a1[i]])\n",
    "    df_ver_r[i] = pd.concat([df_ver_r[i], a2[i]])\n",
    "    df_ver_r[i] = pd.concat([df_ver_r[i], a3[i]])\n",
    "\n",
    "    df_ver_r[i]['Decision Consistency'] = [\"\" for _ in range(54)]\n",
    "    df_ver_r[i]['Belief Consistency'] = [\"\" for _ in range(54)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "24d2d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ver_r[0].reset_index(drop=True).to_csv('../human_verification/resp-s1.csv', columns=['Proposal', 'Responder Belief', 'Decision', 'Responder Reasoning', 'Decision Consistency', 'Belief Consistency'])\n",
    "df_ver_r[1].reset_index(drop=True).to_csv('../human_verification/resp-s2.csv', columns=['Proposal', 'Responder Belief', 'Decision', 'Responder Reasoning', 'Decision Consistency', 'Belief Consistency'])\n",
    "df_ver_r[2].reset_index(drop=True).to_csv('../human_verification/resp-s3.csv', columns=['Proposal', 'Responder Belief', 'Decision', 'Responder Reasoning', 'Decision Consistency', 'Belief Consistency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a39dec3",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "061c470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = pd.read_csv('../human_verification/prop-s1.csv')\n",
    "p2 = pd.read_csv('../human_verification/prop-s2.csv')\n",
    "p3 = pd.read_csv('../human_verification/prop-s3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad852c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1['q1'] = p1.apply(lambda x: 1 if 'yes' in x['q1'] else 0, axis=1)\n",
    "p1['q2'] = p1.apply(lambda x: 1 if 'yes' in x['q2'] else 0, axis=1)\n",
    "\n",
    "p2['q1'] = p2.apply(lambda x: 1 if 'yes' in x['q1'] else 0, axis=1)\n",
    "p2['q2'] = p2.apply(lambda x: 1 if 'yes' in x['q2'] else 0, axis=1)\n",
    "\n",
    "p3['q1'] = p3.apply(lambda x: 1 if 'yes' in x['q1'] else 0, axis=1)\n",
    "p3['q2'] = p3.apply(lambda x: 1 if 'yes' in x['q2'] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b31ab1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = pd.read_csv('../human_verification/resp-s1.csv')\n",
    "r2 = pd.read_csv('../human_verification/resp-s2.csv')\n",
    "r3 = pd.read_csv('../human_verification/resp-s3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1622a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1['q1'] = r1.apply(lambda x: 1 if 'yes' in x['q1'] else 0, axis=1)\n",
    "r1['q2'] = r1.apply(lambda x: 1 if 'yes' in x['q2'] else 0, axis=1)\n",
    "\n",
    "r2['q1'] = r2.apply(lambda x: 1 if 'yes' in x['q1'] else 0, axis=1)\n",
    "r2['q2'] = r2.apply(lambda x: 1 if 'yes' in x['q2'] else 0, axis=1)\n",
    "\n",
    "r3['q1'] = r3.apply(lambda x: 1 if 'yes' in x['q1'] else 0, axis=1)\n",
    "r3['q2'] = r3.apply(lambda x: 1 if 'yes' in x['q2'] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2351179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_p1 = pd.read_csv('../human_verification/responses/prop-s1.csv')\n",
    "h_p2 = pd.read_excel('../human_verification/responses/prop-s2.xlsx')\n",
    "h_p3 = pd.read_csv('../human_verification/responses/prop-s3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c644aa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_p1['Proposal Consistency'] = h_p1.apply(lambda x: 1 if 'yes' in x['Proposal Consistency'] else 0, axis=1)\n",
    "h_p1['Belief Consistency'] = h_p1.apply(lambda x: 1 if 'yes' in x['Belief Consistency'] else 0, axis=1)\n",
    "\n",
    "h_p2['Proposal Consistency'] = h_p2.apply(lambda x: 1 if 'yes' in x['Proposal Consistency'] else 0, axis=1)\n",
    "h_p2['Belief Consistency'] = h_p2.apply(lambda x: 1 if 'yes' in x['Belief Consistency'] else 0, axis=1)\n",
    "\n",
    "h_p3['Proposal Consistency'] = h_p3.apply(lambda x: 1 if 'yes' in x['Proposal Consistency'] else 0, axis=1)\n",
    "h_p3['Belief Consistency'] = h_p3.apply(lambda x: 1 if 'yes' in x['Belief Consistency'] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1b4219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_r1 = pd.read_csv('../human_verification/responses/resp-s1.csv')\n",
    "h_r2 = pd.read_excel('../human_verification/responses/resp-s2.xlsx')\n",
    "h_r3 = pd.read_csv('../human_verification/responses/resp-s3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37b8aabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_r1['Decision Consistency'] = h_r1.apply(lambda x: 1 if 'yes' in x['Decision Consistency'] else 0, axis=1)\n",
    "h_r1['Belief Consistency'] = h_r1.apply(lambda x: 1 if 'yes' in x['Belief Consistency'] else 0, axis=1)\n",
    "\n",
    "h_r2['Decision Consistency'] = h_r2.apply(lambda x: 1 if 'yes' in x['Decision Consistency'] else 0, axis=1)\n",
    "h_r2['Belief Consistency'] = h_r2.apply(lambda x: 1 if 'yes' in x['Belief Consistency'] else 0, axis=1)\n",
    "\n",
    "h_r3['Decision Consistency'] = h_r3.apply(lambda x: 1 if 'yes' in x['Decision Consistency'] else 0, axis=1)\n",
    "h_r3['Belief Consistency'] = h_r3.apply(lambda x: 1 if 'yes' in x['Belief Consistency'] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0a4c7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7962962962962963)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([h_r3['Decision Consistency'].mean(), h_r3['Belief Consistency'].mean(), h_p3['Proposal Consistency'].mean(), h_p3['Belief Consistency'].mean()])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce3872a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8518518518518519)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([h_r2['Decision Consistency'].mean(), h_r2['Belief Consistency'].mean(), h_p2['Proposal Consistency'].mean(), h_p2['Belief Consistency'].mean()])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b96a7820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6898148148148149)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([h_r1['Decision Consistency'].mean(), h_r1['Belief Consistency'].mean(), h_p1['Proposal Consistency'].mean(), h_p1['Belief Consistency'].mean()])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0647ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claude-3-5-haiku-20241022\n",
      "('greedy', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('fair', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('greedy', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('selfless', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('selfless', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('greedy', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('fair', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('fair', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('selfless', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "deepseek-r1-distill-qwen-32b\n",
      "('greedy', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('fair', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('greedy', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('selfless', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('selfless', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('greedy', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('fair', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('fair', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('selfless', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "gpt-4o\n",
      "('greedy', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('fair', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('greedy', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('selfless', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('selfless', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('greedy', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('fair', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('fair', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('selfless', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "gpt-4o-mini\n",
      "('greedy', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('fair', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('greedy', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('selfless', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('selfless', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('greedy', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('fair', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('fair', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('selfless', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "llama-3.1-8b-instant\n",
      "('greedy', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('fair', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('greedy', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('selfless', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('selfless', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('greedy', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('fair', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('fair', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('selfless', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "llama-3.3-70b-versatile\n",
      "('greedy', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('fair', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('greedy', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('selfless', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('selfless', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('greedy', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('fair', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('fair', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('selfless', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "o3-mini\n",
      "('greedy', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('fair', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('greedy', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('selfless', 'greedy')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('selfless', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('greedy', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('fair', 'fair')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('fair', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n",
      "('selfless', 'selfless')\n",
      "belief_private_tom-both\n",
      "belief_private_tom-first\n",
      "belief_private_tom-zero\n"
     ]
    }
   ],
   "source": [
    "df = {\n",
    "    'Model': [],\n",
    "    'Experiment': [],\n",
    "    'Proposer Belief': [],\n",
    "    'Responder Belief': [],\n",
    "    'Proposal': [],\n",
    "    'Proposer Reasoning': [],\n",
    "    'Decision': [],\n",
    "    'Responder Reasoning': []\n",
    "}\n",
    "\n",
    "for model in os.listdir('../simulations'):\n",
    "    print(model)\n",
    "    curr_dir = os.path.join('../simulations', model)\n",
    "\n",
    "    if not os.path.isdir(curr_dir):\n",
    "        continue\n",
    "\n",
    "    for setting in [('greedy', 'fair'), ('fair', 'greedy'), ('greedy', 'greedy'), ('selfless', 'greedy'), ('selfless', 'fair'), ('greedy', 'selfless'), ('fair', 'fair'), ('fair', 'selfless'), ('selfless', 'selfless')]:\n",
    "        print(setting)\n",
    "        set_dir = os.path.join(curr_dir, f'{setting[0]}-{setting[1]}')\n",
    "\n",
    "        if not os.path.isdir(set_dir):\n",
    "            continue\n",
    "\n",
    "        for exp in os.listdir(set_dir):\n",
    "            if 'tom' not in exp:\n",
    "                continue\n",
    "            print(exp)\n",
    "            exp_dir = os.path.join(set_dir, exp)\n",
    "            if not os.path.isdir(exp_dir):\n",
    "                continue\n",
    "            \n",
    "            for session in range(10):\n",
    "                try:\n",
    "                    with open(os.path.join(exp_dir, f'{session+1}.json'), 'r') as f:\n",
    "                        data = json.load(f)\n",
    "                    f.close()\n",
    "\n",
    "                    for turn in range(len(data)):\n",
    "                        curr = data[turn]\n",
    "\n",
    "                        df['Model'].append(model)\n",
    "                        df['Experiment'].append(exp.replace('belief_private_', ''))\n",
    "                        df['Proposer Belief'].append(setting[0])\n",
    "                        df['Responder Belief'].append(setting[1])\n",
    "                        df['Proposal'].append(curr['proposer'])\n",
    "                        df['Proposer Reasoning'].append(curr['proposer_tom'])\n",
    "                        df['Decision'].append(curr['responder'])\n",
    "                        df['Responder Reasoning'].append(curr['responder_tom'])\n",
    "                except FileNotFoundError as e:\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2de9bbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "639d3b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1['reasoning_type'] = ['' for _ in range(p1.shape[0])]\n",
    "p2['reasoning_type'] = ['' for _ in range(p2.shape[0])]\n",
    "\n",
    "p1['model'] = ['' for _ in range(p1.shape[0])]\n",
    "p2['model'] = ['' for _ in range(p2.shape[0])]\n",
    "\n",
    "p3['reasoning_type'] = ['' for _ in range(p3.shape[0])]\n",
    "p3['model'] = ['' for _ in range(p3.shape[0])]\n",
    "\n",
    "r1['reasoning_type'] = ['' for _ in range(r1.shape[0])]\n",
    "r2['reasoning_type'] = ['' for _ in range(r2.shape[0])]\n",
    "\n",
    "r1['model'] = ['' for _ in range(r1.shape[0])]\n",
    "r2['model'] = ['' for _ in range(r2.shape[0])]\n",
    "\n",
    "r3['reasoning_type'] = ['' for _ in range(r3.shape[0])]\n",
    "r3['model'] = ['' for _ in range(r3.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e616522",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasonings = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    for j in range(len(p1)):\n",
    "        if p1['Proposer Reasoning'][j] == df['Proposer Reasoning'][i] and p1['Proposer Belief'][j] == df['Proposer Belief'][i]:\n",
    "            p1.at[j, 'reasoning_type'] = df['Experiment'][i]\n",
    "            p1.at[j, 'model'] = df['Model'][i]\n",
    "        \n",
    "        if p2['Proposer Reasoning'][j] == df['Proposer Reasoning'][i] and p2['Proposer Belief'][j] == df['Proposer Belief'][i]:\n",
    "            p2.at[j, 'reasoning_type'] = df['Experiment'][i]\n",
    "            p2.at[j, 'model'] = df['Model'][i]\n",
    "        \n",
    "        if p3['Proposer Reasoning'][j] == df['Proposer Reasoning'][i] and p3['Proposer Belief'][j] == df['Proposer Belief'][i]:\n",
    "            p3.at[j, 'reasoning_type'] = df['Experiment'][i]\n",
    "            p3.at[j, 'model'] = df['Model'][i]\n",
    "        \n",
    "\n",
    "        if r1['Responder Reasoning'][j] == df['Responder Reasoning'][i] and r1['Responder Belief'][j] == df['Responder Belief'][i]:\n",
    "            r1.at[j, 'reasoning_type'] = df['Experiment'][i]\n",
    "            r1.at[j, 'model'] = df['Model'][i]\n",
    "        \n",
    "        if r2['Responder Reasoning'][j] == df['Responder Reasoning'][i] and r2['Responder Belief'][j] == df['Responder Belief'][i]:\n",
    "            r2.at[j, 'reasoning_type'] = df['Experiment'][i]\n",
    "            r2.at[j, 'model'] = df['Model'][i]\n",
    "\n",
    "        if r3['Responder Reasoning'][j] == df['Responder Reasoning'][i] and r3['Responder Belief'][j] == df['Responder Belief'][i]:\n",
    "            r3.at[j, 'reasoning_type'] = df['Experiment'][i]\n",
    "            r3.at[j, 'model'] = df['Model'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04512c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Proposer Belief</th>\n",
       "      <th>Responder Belief</th>\n",
       "      <th>Proposal</th>\n",
       "      <th>Proposer Reasoning</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Responder Reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>claude-3-5-haiku-20241022</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>greedy</td>\n",
       "      <td>fair</td>\n",
       "      <td>Proposal: I get $9 and you get $1</td>\n",
       "      <td>Round 1 Reasoning:\\n\\n1. My Beliefs:\\n- As a g...</td>\n",
       "      <td>Based on my previous reasoning and analysis, w...</td>\n",
       "      <td>Let me analyze the situation based on the give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claude-3-5-haiku-20241022</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>greedy</td>\n",
       "      <td>fair</td>\n",
       "      <td>Proposal: I get $7 and you get $3</td>\n",
       "      <td>Round 2 Reasoning:\\n\\n1. My Beliefs:\\n- My ini...</td>\n",
       "      <td>Based on my previous reasoning and analysis, w...</td>\n",
       "      <td>Let me analyze the new proposal:\\n\\n1. My beli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claude-3-5-haiku-20241022</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>greedy</td>\n",
       "      <td>fair</td>\n",
       "      <td>Proposal: I get $6 and you get $4</td>\n",
       "      <td>Round 3 Reasoning:\\n\\n1. My Beliefs:\\n- Player...</td>\n",
       "      <td>Based on my previous reasoning and analysis, w...</td>\n",
       "      <td>Let me analyze the new proposal:\\n\\n1. My beli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>claude-3-5-haiku-20241022</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>greedy</td>\n",
       "      <td>fair</td>\n",
       "      <td>Proposal: I get $5 and you get $5</td>\n",
       "      <td>Round 4 Reasoning:\\n\\n1. My Beliefs:\\n- Player...</td>\n",
       "      <td>Based on my previous reasoning and analysis, w...</td>\n",
       "      <td>Let me analyze the new proposal:\\n\\n1. My beli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>claude-3-5-haiku-20241022</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>greedy</td>\n",
       "      <td>fair</td>\n",
       "      <td>Based on my reasoning and belief of being a gr...</td>\n",
       "      <td>Let me analyze the situation based on the give...</td>\n",
       "      <td>Based on my previous reasoning and analysis of...</td>\n",
       "      <td>Let me analyze the situation carefully:\\n\\n1. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4930</th>\n",
       "      <td>o3-mini</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>selfless</td>\n",
       "      <td>selfless</td>\n",
       "      <td>Proposal: I get $0 and you get $10.</td>\n",
       "      <td>I'm sorry, but I can't share details about my ...</td>\n",
       "      <td>Decision: Accept</td>\n",
       "      <td>I'm sorry, but I can’t share details about my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>o3-mini</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>selfless</td>\n",
       "      <td>selfless</td>\n",
       "      <td>Proposal: I get $0 and you get $10.</td>\n",
       "      <td>I'm sorry, but I can't share that information.</td>\n",
       "      <td>Decision: Accept</td>\n",
       "      <td>I'm sorry, but I can’t share details about my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4932</th>\n",
       "      <td>o3-mini</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>selfless</td>\n",
       "      <td>selfless</td>\n",
       "      <td>Proposal: I get $0 and you get $10</td>\n",
       "      <td>I'm sorry, but I can’t share details about my ...</td>\n",
       "      <td>Decision: Accept</td>\n",
       "      <td>I'm sorry, but I can’t share details about my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4933</th>\n",
       "      <td>o3-mini</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>selfless</td>\n",
       "      <td>selfless</td>\n",
       "      <td>Proposal: I get $0 and you get $10.</td>\n",
       "      <td>I'm sorry, but I can't share details about my ...</td>\n",
       "      <td>Decision: Accept</td>\n",
       "      <td>I'm sorry, but I can’t share details about my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4934</th>\n",
       "      <td>o3-mini</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>selfless</td>\n",
       "      <td>selfless</td>\n",
       "      <td>Proposal: I get $0 and you get $10.</td>\n",
       "      <td>I'm sorry, but I can't share details about my ...</td>\n",
       "      <td>Decision: Accept</td>\n",
       "      <td>I'm sorry, but I can’t share details about my ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4935 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model Experiment Proposer Belief Responder Belief  \\\n",
       "0     claude-3-5-haiku-20241022   tom-both          greedy             fair   \n",
       "1     claude-3-5-haiku-20241022   tom-both          greedy             fair   \n",
       "2     claude-3-5-haiku-20241022   tom-both          greedy             fair   \n",
       "3     claude-3-5-haiku-20241022   tom-both          greedy             fair   \n",
       "4     claude-3-5-haiku-20241022   tom-both          greedy             fair   \n",
       "...                         ...        ...             ...              ...   \n",
       "4930                    o3-mini   tom-zero        selfless         selfless   \n",
       "4931                    o3-mini   tom-zero        selfless         selfless   \n",
       "4932                    o3-mini   tom-zero        selfless         selfless   \n",
       "4933                    o3-mini   tom-zero        selfless         selfless   \n",
       "4934                    o3-mini   tom-zero        selfless         selfless   \n",
       "\n",
       "                                               Proposal  \\\n",
       "0                     Proposal: I get $9 and you get $1   \n",
       "1                     Proposal: I get $7 and you get $3   \n",
       "2                     Proposal: I get $6 and you get $4   \n",
       "3                     Proposal: I get $5 and you get $5   \n",
       "4     Based on my reasoning and belief of being a gr...   \n",
       "...                                                 ...   \n",
       "4930                Proposal: I get $0 and you get $10.   \n",
       "4931                Proposal: I get $0 and you get $10.   \n",
       "4932                 Proposal: I get $0 and you get $10   \n",
       "4933                Proposal: I get $0 and you get $10.   \n",
       "4934                Proposal: I get $0 and you get $10.   \n",
       "\n",
       "                                     Proposer Reasoning  \\\n",
       "0     Round 1 Reasoning:\\n\\n1. My Beliefs:\\n- As a g...   \n",
       "1     Round 2 Reasoning:\\n\\n1. My Beliefs:\\n- My ini...   \n",
       "2     Round 3 Reasoning:\\n\\n1. My Beliefs:\\n- Player...   \n",
       "3     Round 4 Reasoning:\\n\\n1. My Beliefs:\\n- Player...   \n",
       "4     Let me analyze the situation based on the give...   \n",
       "...                                                 ...   \n",
       "4930  I'm sorry, but I can't share details about my ...   \n",
       "4931     I'm sorry, but I can't share that information.   \n",
       "4932  I'm sorry, but I can’t share details about my ...   \n",
       "4933  I'm sorry, but I can't share details about my ...   \n",
       "4934  I'm sorry, but I can't share details about my ...   \n",
       "\n",
       "                                               Decision  \\\n",
       "0     Based on my previous reasoning and analysis, w...   \n",
       "1     Based on my previous reasoning and analysis, w...   \n",
       "2     Based on my previous reasoning and analysis, w...   \n",
       "3     Based on my previous reasoning and analysis, w...   \n",
       "4     Based on my previous reasoning and analysis of...   \n",
       "...                                                 ...   \n",
       "4930                                   Decision: Accept   \n",
       "4931                                   Decision: Accept   \n",
       "4932                                   Decision: Accept   \n",
       "4933                                   Decision: Accept   \n",
       "4934                                   Decision: Accept   \n",
       "\n",
       "                                    Responder Reasoning  \n",
       "0     Let me analyze the situation based on the give...  \n",
       "1     Let me analyze the new proposal:\\n\\n1. My beli...  \n",
       "2     Let me analyze the new proposal:\\n\\n1. My beli...  \n",
       "3     Let me analyze the new proposal:\\n\\n1. My beli...  \n",
       "4     Let me analyze the situation carefully:\\n\\n1. ...  \n",
       "...                                                 ...  \n",
       "4930  I'm sorry, but I can’t share details about my ...  \n",
       "4931  I'm sorry, but I can’t share details about my ...  \n",
       "4932  I'm sorry, but I can’t share details about my ...  \n",
       "4933  I'm sorry, but I can’t share details about my ...  \n",
       "4934  I'm sorry, but I can’t share details about my ...  \n",
       "\n",
       "[4935 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "404afa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_p1['reasoning_type'] = p1['reasoning_type']\n",
    "h_p2['reasoning_type'] = p2['reasoning_type']\n",
    "\n",
    "h_r1['reasoning_type'] = r1['reasoning_type']\n",
    "h_r2['reasoning_type'] = r2['reasoning_type']\n",
    "\n",
    "h_r3['reasoning_type'] = r3['reasoning_type']\n",
    "h_p3['reasoning_type'] = p3['reasoning_type']\n",
    "\n",
    "\n",
    "h_p1['model'] = p1['model']\n",
    "h_p2['model'] = p2['model']\n",
    "\n",
    "h_r1['model'] = r1['model']\n",
    "h_r2['model'] = r2['model']\n",
    "\n",
    "h_r3['model'] = r3['model']\n",
    "h_p3['model'] = p3['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9e315b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Proposal Consistency</th>\n",
       "      <th>Belief Consistency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reasoning_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tom-both</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.907407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tom-first</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tom-zero</th>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.907407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Proposal Consistency  Belief Consistency\n",
       "reasoning_type                                          \n",
       "tom-both                    0.629630            0.907407\n",
       "tom-first                   0.555556            0.740741\n",
       "tom-zero                    0.722222            0.907407"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggregate columns by reasoning_type for each df\n",
    "pd.concat([h_p1, h_p2, h_p3]).groupby('reasoning_type').agg({\n",
    "    'Proposal Consistency': 'mean',\n",
    "    'Belief Consistency': 'mean',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d408a29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Proposal Consistency</th>\n",
       "      <th>Belief Consistency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deepseek-r1-distill-qwen-32b</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.759259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-3.3-70b-versatile</th>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.907407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Proposal Consistency  Belief Consistency\n",
       "model                                                                 \n",
       "deepseek-r1-distill-qwen-32b              0.629630            0.888889\n",
       "gpt-4o                                    0.592593            0.759259\n",
       "llama-3.3-70b-versatile                   0.685185            0.907407"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([h_p1, h_p2, h_p3]).groupby('model').agg({\n",
    "    'Proposal Consistency': 'mean',\n",
    "    'Belief Consistency': 'mean',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e60adb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decision Consistency</th>\n",
       "      <th>Belief Consistency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reasoning_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.876543</td>\n",
       "      <td>0.753086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Decision Consistency  Belief Consistency\n",
       "reasoning_type                                          \n",
       "                            0.876543            0.753086"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([h_r1, h_r2, h_r3]).groupby('reasoning_type').agg({\n",
    "    'Decision Consistency': 'mean',\n",
    "    'Belief Consistency': 'mean',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2de933a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decision Consistency</th>\n",
       "      <th>Belief Consistency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deepseek-r1-distill-qwen-32b</th>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.685185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-3.3-70b-versatile</th>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Decision Consistency  Belief Consistency\n",
       "model                                                                 \n",
       "deepseek-r1-distill-qwen-32b              0.944444            0.685185\n",
       "gpt-4o                                    0.814815            0.740741\n",
       "llama-3.3-70b-versatile                   0.870370            0.833333"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([h_r1, h_r2, h_r3]).groupby('model').agg({\n",
    "    'Decision Consistency': 'mean',\n",
    "    'Belief Consistency': 'mean',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5bcc6ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deepseek-r1-distill-qwen-32b</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.759259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.685185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-3.3-70b-versatile</th>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.870370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    q1        q2\n",
       "model                                           \n",
       "deepseek-r1-distill-qwen-32b  0.611111  0.759259\n",
       "gpt-4o                        0.740741  0.685185\n",
       "llama-3.3-70b-versatile       0.851852  0.870370"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([p1, p2, p3]).groupby('model').agg({\n",
    "    'q1': 'mean',\n",
    "    'q2': 'mean',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "46aae2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reasoning_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tom-both</th>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.796296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tom-first</th>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tom-zero</th>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.796296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      q1        q2\n",
       "reasoning_type                    \n",
       "tom-both        0.740741  0.796296\n",
       "tom-first       0.740741  0.722222\n",
       "tom-zero        0.722222  0.796296"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([p1, p2, p3]).groupby('reasoning_type').agg({\n",
    "    'q1': 'mean',\n",
    "    'q2': 'mean',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a4c5a807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deepseek-r1-distill-qwen-32b</th>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.703704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-3.3-70b-versatile</th>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    q1        q2\n",
       "model                                           \n",
       "deepseek-r1-distill-qwen-32b  0.962963  0.703704\n",
       "gpt-4o                        0.888889  0.722222\n",
       "llama-3.3-70b-versatile       0.962963  0.777778"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([r1, r2, r3]).groupby('model').agg({\n",
    "    'q1': 'mean',\n",
    "    'q2': 'mean',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4659d51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reasoning_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tom-both</th>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tom-first</th>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tom-zero</th>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.851852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      q1        q2\n",
       "reasoning_type                    \n",
       "tom-both        0.962963  0.740741\n",
       "tom-first       0.925926  0.611111\n",
       "tom-zero        0.925926  0.851852"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([r1, r2, r3]).groupby('reasoning_type').agg({\n",
    "    'q1': 'mean',\n",
    "    'q2': 'mean',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4392071e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reasoning_type\n",
       "tom-first    22\n",
       "tom-zero     19\n",
       "tom-both     13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_r3['reasoning_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "104a4460",
   "metadata": {},
   "outputs": [],
   "source": [
    "pq1_annot = {\n",
    "    'p1_q1_h': h_p1['Proposal Consistency'].values.tolist(),\n",
    "    'p1_q1': p1['q1'].values.tolist(),\n",
    "    'p2_q1_h': h_p2['Proposal Consistency'].values.tolist(),\n",
    "    'p2_q1': p2['q1'].values.tolist(),\n",
    "    'p3_q1_h': h_p3['Proposal Consistency'].values.tolist(),\n",
    "    'p3_q1': p3['q1'].values.tolist(),\n",
    "    'm1': p1['model'].values.tolist(),\n",
    "    'm2': p2['model'].values.tolist(),\n",
    "    'm3': p3['model'].values.tolist(),\n",
    "    'rt1': p1['reasoning_type'].values.tolist(),\n",
    "    'rt2': p2['reasoning_type'].values.tolist(),\n",
    "    'rt3': p3['reasoning_type'].values.tolist(),\n",
    "}\n",
    "\n",
    "pq2_annot = {\n",
    "    'p1_q2_h': h_p1['Belief Consistency'].values.tolist(),\n",
    "    'p1_q2': p1['q2'].values.tolist(),\n",
    "    'p2_q2_h': h_p2['Belief Consistency'].values.tolist(),\n",
    "    'p2_q2': p2['q2'].values.tolist(),\n",
    "    'p3_q2_h': h_p3['Belief Consistency'].values.tolist(),\n",
    "    'p3_q2': p3['q2'].values.tolist(),\n",
    "    'm1': p1['model'].values.tolist(),\n",
    "    'm2': p2['model'].values.tolist(),\n",
    "    'm3': p3['model'].values.tolist(),\n",
    "    'rt1': p1['reasoning_type'].values.tolist(),\n",
    "    'rt2': p2['reasoning_type'].values.tolist(),\n",
    "    'rt3': p3['reasoning_type'].values.tolist(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "29d0eeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rq1_annot = {\n",
    "    'r1_q1_h': h_r1['Decision Consistency'].values.tolist(),\n",
    "    'r1_q1': r1['q1'].values.tolist(),\n",
    "    'r2_q1_h': h_r2['Decision Consistency'].values.tolist(),\n",
    "    'r2_q1': r2['q1'].values.tolist(),\n",
    "    'r3_q1_h': h_r3['Decision Consistency'].values.tolist(),\n",
    "    'r3_q1': r3['q1'].values.tolist(),\n",
    "    'm1': r1['model'].values.tolist(),\n",
    "    'm2': r2['model'].values.tolist(),\n",
    "    'm3': r3['model'].values.tolist(),\n",
    "    'rt1': r1['reasoning_type'].values.tolist(),\n",
    "    'rt2': r2['reasoning_type'].values.tolist(),\n",
    "    'rt3': r3['reasoning_type'].values.tolist(),\n",
    "}\n",
    "\n",
    "rq2_annot = {\n",
    "    'r1_q2_h': h_r1['Belief Consistency'].values.tolist(),\n",
    "    'r1_q2': r1['q2'].values.tolist(),\n",
    "    'r2_q2_h': h_r2['Belief Consistency'].values.tolist(),\n",
    "    'r2_q2': r2['q2'].values.tolist(),\n",
    "    'r3_q2_h': h_r3['Belief Consistency'].values.tolist(),\n",
    "    'r3_q2': r3['q2'].values.tolist(),\n",
    "    'm1': r1['model'].values.tolist(),\n",
    "    'm2': r2['model'].values.tolist(),\n",
    "    'm3': r3['model'].values.tolist(),\n",
    "    'rt1': r1['reasoning_type'].values.tolist(),\n",
    "    'rt2': r2['reasoning_type'].values.tolist(),\n",
    "    'rt3': r3['reasoning_type'].values.tolist(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "06621db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pq1 = pd.DataFrame(pq1_annot)\n",
    "pq2 = pd.DataFrame(pq2_annot)\n",
    "\n",
    "rq1 = pd.DataFrame(rq1_annot)\n",
    "rq2 = pd.DataFrame(rq2_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7fb10d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting krippendorff\n",
      "  Using cached krippendorff-0.8.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.21 in /Users/neemeshyadav/miniconda/envs/venv/lib/python3.12/site-packages (from krippendorff) (1.26.4)\n",
      "Using cached krippendorff-0.8.1-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: krippendorff\n",
      "Successfully installed krippendorff-0.8.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install krippendorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "14dbfee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall = np.array([x1[:, 0], x1[:, 1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "555789ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall = np.concatenate((overall, np.array([x2[:, 0], x2[:, 1]]).T), axis=0)\n",
    "overall = np.concatenate((overall, np.array([x3[:, 0], x3[:, 1]]).T), axis=0)\n",
    "\n",
    "overall = np.concatenate((overall, np.array([x1[:, 2], x1[:, 3]]).T), axis=0)\n",
    "overall = np.concatenate((overall, np.array([x1[:, 4], x3[:, 5]]).T), axis=0)\n",
    "overall = np.concatenate((overall, np.array([x2[:, 2], x2[:, 3]]).T), axis=0)\n",
    "overall = np.concatenate((overall, np.array([x2[:, 4], x2[:, 5]]).T), axis=0)\n",
    "overall = np.concatenate((overall, np.array([x3[:, 2], x3[:, 3]]).T), axis=0)\n",
    "overall = np.concatenate((overall, np.array([x3[:, 4], x3[:, 5]]).T), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "da3bfc63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30526094276094284"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "krippendorff.alpha(overall.T, level_of_measurement='nominal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b7f05d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import krippendorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "71f351ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "4a2aca7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1_q1_h</th>\n",
       "      <th>p1_q1</th>\n",
       "      <th>p2_q1_h</th>\n",
       "      <th>p2_q1</th>\n",
       "      <th>p3_q1_h</th>\n",
       "      <th>p3_q1</th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>m3</th>\n",
       "      <th>rt1</th>\n",
       "      <th>rt2</th>\n",
       "      <th>rt3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>tom-first</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>tom-both</td>\n",
       "      <td>tom-zero</td>\n",
       "      <td>tom-first</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    p1_q1_h  p1_q1  p2_q1_h  p2_q1  p3_q1_h  p3_q1  \\\n",
       "0         1      1        0      0        1      1   \n",
       "1         1      1        1      1        0      0   \n",
       "2         1      0        0      0        0      0   \n",
       "3         0      0        0      0        1      1   \n",
       "4         1      1        0      1        0      0   \n",
       "5         1      1        1      1        0      0   \n",
       "6         0      0        1      1        0      0   \n",
       "7         1      1        1      1        0      0   \n",
       "8         1      1        1      1        1      1   \n",
       "9         1      1        0      1        1      1   \n",
       "10        1      1        1      1        1      1   \n",
       "11        1      1        0      0        1      1   \n",
       "12        0      0        1      1        1      1   \n",
       "13        0      0        1      1        1      1   \n",
       "14        0      0        1      1        1      1   \n",
       "15        0      0        0      0        1      1   \n",
       "16        1      0        0      0        1      1   \n",
       "17        1      1        1      1        1      0   \n",
       "18        0      0        1      1        1      1   \n",
       "19        0      0        1      1        1      1   \n",
       "20        0      1        1      1        1      1   \n",
       "21        0      0        1      1        0      0   \n",
       "22        0      1        1      1        1      1   \n",
       "23        1      0        1      1        1      0   \n",
       "24        1      1        1      1        1      0   \n",
       "25        0      1        1      1        0      0   \n",
       "26        0      1        1      1        1      1   \n",
       "27        0      1        0      1        1      1   \n",
       "28        0      1        1      1        1      1   \n",
       "29        0      1        0      0        1      1   \n",
       "30        1      1        0      1        1      0   \n",
       "31        1      1        0      1        0      0   \n",
       "32        0      1        1      0        1      1   \n",
       "33        1      1        1      1        0      0   \n",
       "34        0      1        1      1        0      1   \n",
       "35        0      1        1      0        1      1   \n",
       "36        0      0        1      1        1      1   \n",
       "37        0      1        1      1        1      1   \n",
       "38        1      1        0      1        0      1   \n",
       "39        0      0        1      0        1      1   \n",
       "40        1      1        1      1        1      1   \n",
       "41        0      1        1      1        1      1   \n",
       "42        0      1        1      1        0      1   \n",
       "43        1      1        1      1        1      1   \n",
       "44        0      0        1      1        1      0   \n",
       "45        0      1        1      1        1      1   \n",
       "46        0      1        1      1        1      1   \n",
       "47        0      0        1      1        1      1   \n",
       "48        0      0        1      1        1      0   \n",
       "49        1      1        1      1        0      1   \n",
       "50        0      1        1      1        1      1   \n",
       "51        1      1        1      1        1      1   \n",
       "52        0      1        1      1        1      1   \n",
       "53        0      1        1      1        1      1   \n",
       "\n",
       "                              m1                            m2  \\\n",
       "0   deepseek-r1-distill-qwen-32b  deepseek-r1-distill-qwen-32b   \n",
       "1   deepseek-r1-distill-qwen-32b  deepseek-r1-distill-qwen-32b   \n",
       "2   deepseek-r1-distill-qwen-32b  deepseek-r1-distill-qwen-32b   \n",
       "3   deepseek-r1-distill-qwen-32b  deepseek-r1-distill-qwen-32b   \n",
       "4   deepseek-r1-distill-qwen-32b  deepseek-r1-distill-qwen-32b   \n",
       "5   deepseek-r1-distill-qwen-32b  deepseek-r1-distill-qwen-32b   \n",
       "6   deepseek-r1-distill-qwen-32b  deepseek-r1-distill-qwen-32b   \n",
       "7   deepseek-r1-distill-qwen-32b  deepseek-r1-distill-qwen-32b   \n",
       "8   deepseek-r1-distill-qwen-32b  deepseek-r1-distill-qwen-32b   \n",
       "9   deepseek-r1-distill-qwen-32b  deepseek-r1-distill-qwen-32b   \n",
       "10  deepseek-r1-distill-qwen-32b  deepseek-r1-distill-qwen-32b   \n",
       "11  deepseek-r1-distill-qwen-32b  deepseek-r1-distill-qwen-32b   \n",
       "12  deepseek-r1-distill-qwen-32b  deepseek-r1-distill-qwen-32b   \n",
       "13  deepseek-r1-distill-qwen-32b  deepseek-r1-distill-qwen-32b   \n",
       "14  deepseek-r1-distill-qwen-32b  deepseek-r1-distill-qwen-32b   \n",
       "15  deepseek-r1-distill-qwen-32b  deepseek-r1-distill-qwen-32b   \n",
       "16  deepseek-r1-distill-qwen-32b  deepseek-r1-distill-qwen-32b   \n",
       "17  deepseek-r1-distill-qwen-32b  deepseek-r1-distill-qwen-32b   \n",
       "18                        gpt-4o                        gpt-4o   \n",
       "19                        gpt-4o                        gpt-4o   \n",
       "20                        gpt-4o                        gpt-4o   \n",
       "21                        gpt-4o                        gpt-4o   \n",
       "22                        gpt-4o                        gpt-4o   \n",
       "23                        gpt-4o                        gpt-4o   \n",
       "24                        gpt-4o                        gpt-4o   \n",
       "25                        gpt-4o                        gpt-4o   \n",
       "26                        gpt-4o                        gpt-4o   \n",
       "27                        gpt-4o                        gpt-4o   \n",
       "28                        gpt-4o                        gpt-4o   \n",
       "29                        gpt-4o                        gpt-4o   \n",
       "30                        gpt-4o                        gpt-4o   \n",
       "31                        gpt-4o                        gpt-4o   \n",
       "32                        gpt-4o                        gpt-4o   \n",
       "33                        gpt-4o                        gpt-4o   \n",
       "34                        gpt-4o                        gpt-4o   \n",
       "35                        gpt-4o                        gpt-4o   \n",
       "36       llama-3.3-70b-versatile       llama-3.3-70b-versatile   \n",
       "37       llama-3.3-70b-versatile       llama-3.3-70b-versatile   \n",
       "38       llama-3.3-70b-versatile       llama-3.3-70b-versatile   \n",
       "39       llama-3.3-70b-versatile       llama-3.3-70b-versatile   \n",
       "40       llama-3.3-70b-versatile       llama-3.3-70b-versatile   \n",
       "41       llama-3.3-70b-versatile       llama-3.3-70b-versatile   \n",
       "42       llama-3.3-70b-versatile       llama-3.3-70b-versatile   \n",
       "43       llama-3.3-70b-versatile       llama-3.3-70b-versatile   \n",
       "44       llama-3.3-70b-versatile       llama-3.3-70b-versatile   \n",
       "45       llama-3.3-70b-versatile       llama-3.3-70b-versatile   \n",
       "46       llama-3.3-70b-versatile       llama-3.3-70b-versatile   \n",
       "47       llama-3.3-70b-versatile       llama-3.3-70b-versatile   \n",
       "48       llama-3.3-70b-versatile       llama-3.3-70b-versatile   \n",
       "49       llama-3.3-70b-versatile       llama-3.3-70b-versatile   \n",
       "50       llama-3.3-70b-versatile       llama-3.3-70b-versatile   \n",
       "51       llama-3.3-70b-versatile       llama-3.3-70b-versatile   \n",
       "52       llama-3.3-70b-versatile       llama-3.3-70b-versatile   \n",
       "53       llama-3.3-70b-versatile       llama-3.3-70b-versatile   \n",
       "\n",
       "                              m3        rt1        rt2        rt3  \n",
       "0   deepseek-r1-distill-qwen-32b   tom-zero   tom-zero   tom-both  \n",
       "1   deepseek-r1-distill-qwen-32b  tom-first  tom-first  tom-first  \n",
       "2   deepseek-r1-distill-qwen-32b   tom-zero   tom-zero   tom-both  \n",
       "3   deepseek-r1-distill-qwen-32b   tom-both   tom-both   tom-both  \n",
       "4   deepseek-r1-distill-qwen-32b   tom-zero  tom-first  tom-first  \n",
       "5   deepseek-r1-distill-qwen-32b  tom-first  tom-first  tom-first  \n",
       "6   deepseek-r1-distill-qwen-32b   tom-zero   tom-both   tom-zero  \n",
       "7   deepseek-r1-distill-qwen-32b  tom-first   tom-both   tom-zero  \n",
       "8   deepseek-r1-distill-qwen-32b   tom-zero  tom-first   tom-zero  \n",
       "9   deepseek-r1-distill-qwen-32b  tom-first   tom-both   tom-both  \n",
       "10  deepseek-r1-distill-qwen-32b   tom-zero  tom-first  tom-first  \n",
       "11  deepseek-r1-distill-qwen-32b   tom-both   tom-zero  tom-first  \n",
       "12  deepseek-r1-distill-qwen-32b  tom-first   tom-zero   tom-both  \n",
       "13  deepseek-r1-distill-qwen-32b   tom-zero   tom-both  tom-first  \n",
       "14  deepseek-r1-distill-qwen-32b   tom-both   tom-zero   tom-zero  \n",
       "15  deepseek-r1-distill-qwen-32b   tom-both   tom-both  tom-first  \n",
       "16  deepseek-r1-distill-qwen-32b   tom-zero  tom-first   tom-both  \n",
       "17  deepseek-r1-distill-qwen-32b   tom-both   tom-zero   tom-both  \n",
       "18                        gpt-4o   tom-zero   tom-zero   tom-zero  \n",
       "19                        gpt-4o  tom-first   tom-both   tom-zero  \n",
       "20                        gpt-4o   tom-zero   tom-both   tom-both  \n",
       "21                        gpt-4o   tom-both   tom-both  tom-first  \n",
       "22                        gpt-4o   tom-both   tom-zero   tom-zero  \n",
       "23                        gpt-4o   tom-both   tom-both  tom-first  \n",
       "24                        gpt-4o   tom-zero   tom-both   tom-zero  \n",
       "25                        gpt-4o   tom-both   tom-both  tom-first  \n",
       "26                        gpt-4o  tom-first   tom-both   tom-zero  \n",
       "27                        gpt-4o   tom-both  tom-first   tom-both  \n",
       "28                        gpt-4o  tom-first  tom-first   tom-zero  \n",
       "29                        gpt-4o  tom-first  tom-first  tom-first  \n",
       "30                        gpt-4o   tom-both  tom-first  tom-first  \n",
       "31                        gpt-4o   tom-both  tom-first  tom-first  \n",
       "32                        gpt-4o  tom-first   tom-both   tom-zero  \n",
       "33                        gpt-4o   tom-zero  tom-first   tom-both  \n",
       "34                        gpt-4o   tom-zero   tom-zero  tom-first  \n",
       "35                        gpt-4o   tom-zero   tom-zero   tom-zero  \n",
       "36       llama-3.3-70b-versatile   tom-zero   tom-zero   tom-zero  \n",
       "37       llama-3.3-70b-versatile   tom-both   tom-both   tom-zero  \n",
       "38       llama-3.3-70b-versatile   tom-both  tom-first  tom-first  \n",
       "39       llama-3.3-70b-versatile   tom-both   tom-zero  tom-first  \n",
       "40       llama-3.3-70b-versatile   tom-zero   tom-zero  tom-first  \n",
       "41       llama-3.3-70b-versatile   tom-zero   tom-both   tom-zero  \n",
       "42       llama-3.3-70b-versatile  tom-first  tom-first  tom-first  \n",
       "43       llama-3.3-70b-versatile   tom-zero   tom-zero  tom-first  \n",
       "44       llama-3.3-70b-versatile   tom-zero  tom-first  tom-first  \n",
       "45       llama-3.3-70b-versatile   tom-zero   tom-both   tom-both  \n",
       "46       llama-3.3-70b-versatile   tom-both   tom-both  tom-first  \n",
       "47       llama-3.3-70b-versatile   tom-both  tom-first   tom-both  \n",
       "48       llama-3.3-70b-versatile   tom-both  tom-first  tom-first  \n",
       "49       llama-3.3-70b-versatile   tom-both   tom-both   tom-both  \n",
       "50       llama-3.3-70b-versatile   tom-both  tom-first   tom-zero  \n",
       "51       llama-3.3-70b-versatile   tom-zero   tom-zero  tom-first  \n",
       "52       llama-3.3-70b-versatile  tom-first   tom-both   tom-zero  \n",
       "53       llama-3.3-70b-versatile   tom-both   tom-zero  tom-first  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pq1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ccf4e496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 162)\n",
      "(2, 162)\n",
      "(2, 162)\n",
      "(2, 162)\n",
      "(2, 162)\n",
      "(2, 162)\n",
      "(2, 162)\n",
      "(2, 162)\n",
      "(2, 162)\n",
      "(2, 162)\n",
      "(2, 162)\n",
      "(2, 162)\n"
     ]
    }
   ],
   "source": [
    "alpha_all = {key: [] for key in [\"Component\", \"Proposal Consistency\", \"Proposer Belief Consistency\", \"Decision Consistency\", \"Responder Belief Consistency\"]}\n",
    "\n",
    "for col, data in zip(['Proposal Consistency', 'Proposer Belief Consistency', 'Decision Consistency', 'Responder Belief Consistency'], [pq1, pq2, rq1, rq2]):\n",
    "    for model in ['deepseek-r1-distill-qwen-32b', 'gpt-4o', 'llama-3.3-70b-versatile']:\n",
    "        temp = data[data['m1'] == model].values\n",
    "        \n",
    "        curr_data = np.array([temp[:, 0], temp[:, 1]])\n",
    "        curr_data = np.concatenate((curr_data, np.array([temp[:, 2], temp[:, 3]])), axis=1)\n",
    "        curr_data = np.concatenate((curr_data, np.array([temp[:, 4], temp[:, 5]])), axis=1)\n",
    "\n",
    "        # curr_data = curr_data.T\n",
    "\n",
    "        if model not in alpha_all['Component']:\n",
    "            alpha_all['Component'].append(model)\n",
    "        alpha_all[col].append(round(krippendorff.alpha(reliability_data=curr_data.astype(int), level_of_measurement='nominal'), 2))\n",
    "\n",
    "for col, data in zip(['Proposal Consistency', 'Proposer Belief Consistency', 'Decision Consistency', 'Responder Belief Consistency'], [pq1, pq2, rq1, rq2]):\n",
    "    for r_type in ['tom-zero', 'tom-first', 'tom-both']:\n",
    "        temp = data[data['rt1'] == r_type].values\n",
    "        temp = np.concatenate((temp, data[data['rt2'] == r_type].values), axis=0)\n",
    "        temp = np.concatenate((temp, data[data['rt3'] == r_type].values), axis=0)\n",
    "        \n",
    "        curr_data = np.array([temp[:, 0], temp[:, 1]])\n",
    "        curr_data = np.concatenate((curr_data, np.array([temp[:, 2], temp[:, 3]])), axis=1)\n",
    "        curr_data = np.concatenate((curr_data, np.array([temp[:, 4], temp[:, 5]])), axis=1)\n",
    "\n",
    "        print(curr_data.shape)\n",
    "\n",
    "        # curr_data = curr_data.T\n",
    "\n",
    "        if r_type not in alpha_all['Component']:\n",
    "            alpha_all['Component'].append(r_type)\n",
    "        alpha_all[col].append(round(krippendorff.alpha(reliability_data=curr_data.astype(int), level_of_measurement='nominal'), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c05679e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Component</th>\n",
       "      <th>Proposal Consistency</th>\n",
       "      <th>Proposer Belief Consistency</th>\n",
       "      <th>Decision Consistency</th>\n",
       "      <th>Responder Belief Consistency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tom-zero</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tom-first</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tom-both</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Component  Proposal Consistency  \\\n",
       "0  deepseek-r1-distill-qwen-32b                  0.81   \n",
       "1                        gpt-4o                  0.17   \n",
       "2       llama-3.3-70b-versatile                  0.23   \n",
       "3                      tom-zero                  0.49   \n",
       "4                     tom-first                  0.38   \n",
       "5                      tom-both                  0.41   \n",
       "\n",
       "   Proposer Belief Consistency  Decision Consistency  \\\n",
       "0                         0.30                  0.79   \n",
       "1                         0.27                  0.27   \n",
       "2                        -0.11                  0.16   \n",
       "3                         0.10                  0.48   \n",
       "4                         0.18                  0.29   \n",
       "5                         0.34                  0.24   \n",
       "\n",
       "   Responder Belief Consistency  \n",
       "0                          0.09  \n",
       "1                          0.02  \n",
       "2                          0.47  \n",
       "3                          0.01  \n",
       "4                          0.21  \n",
       "5                          0.23  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(alpha_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3f3a671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.74074074074074\n",
      "75.92592592592592\n",
      "74.07407407407408\n",
      "---\n",
      "81.48148148148148\n",
      "88.88888888888889\n",
      "85.18518518518519\n",
      "---\n",
      "77.77777777777779\n",
      "100.0\n",
      "85.18518518518519\n",
      "---\n",
      "75.92592592592592\n",
      "75.92592592592592\n",
      "74.07407407407408\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "corrs = []\n",
    "\n",
    "for col, df in zip([\"Proposal Consistency\", \"Proposer Belief Consistency\", \"Decision Consistency\", \"Responder Belief Consistency\"], [pq1, pq2, rq1, rq2]):\n",
    "    vals = df.values\n",
    "    print((vals[:, 0] == 1).mean()*100)\n",
    "    print((vals[:, 2] == 1).mean()*100)\n",
    "    print((vals[:, 4] == 1).mean()*100)\n",
    "    \n",
    "    print('---')\n",
    "    # corrs.append(vals[0:2, 0:2])\n",
    "    # corrs.append(vals[2:4, 2:4])\n",
    "    # corrs.append(vals[4:6, 4:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f05c72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
